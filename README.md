# **設計書: マルチモーダルAIを活用した植物診断システム開発**

## **プロジェクトの概要**

MLLM (マルチモーダル大規模モデル)の一つである **Llama 3.2 11B** を使用して、植物診断を行うAIシステムを構築します。主に下記の3つの目的を達成するため、ファインチューニングと量子化技術を組み合わせます。

### **目的**
1. **植物の種類の分類**  
   - データセットに基づき、植物の種類を特定します。
2. **病気・異常の診断**  
   - 画像を解析し、病気や異常を特定します。
3. **具体的な対策の提案**  
   - 診断結果をもとに、有効な対策を提案します。

---

## **開発状況**

### **完了した作業**
1. **環境構築**
   - Python 3.10.11環境の構築
   - 必要なライブラリのインストール
   - GitHubリポジトリの設定

2. **データセット準備**
   - PlantVillage Datasetのダウンロード
   - データの前処理スクリプトの実装
   - 訓練/検証/テストデータの分割（70:15:15）

3. **データ前処理の完了**
   - 38クラスの植物画像データ
   - 合計54,303枚の画像を処理
   - データ拡張の実装（訓練データのみ）

4. **モデルの準備**
   - Llama 3.2 11B Vision-Instructモデルのダウンロード
   - 4-bit量子化の実装と保存
   - 指示データセットの作成（JSONL形式）
     - 訓練データ: 38,012枚
     - 検証データ: 8,145枚
     - テストデータ: 8,146枚

5. **ファインチューニングの実装**
   - LoRAを使用した効率的な学習の実装
   - 画像処理の最適化
     - アスペクト比に基づくタイル分割
     - 動的なパディング処理
   - 評価指標の実装
     - BLEUスコア（テキスト生成評価）
     - マルチクラスF1スコア（分類評価）
   - エラーハンドリングとログ機能の強化
   - Weights & Biasesによる学習モニタリング

6. **学習環境の準備**
   - CUDA 12.4環境の検証
     - GPU: NVIDIA RTX 4070 Ti
     - VRAM: 12GB
     - 計算能力: 8.9
   - Weights & Biases設定
     - プロジェクト名: plant-vision
     - 実験名: llama-3.2-vision-finetune
     - ハイパーパラメータの設定
   - ログ機能の実装
     - 学習進捗の記録
     - エラー監視
     - メモリ使用量の追跡

### **次のステップ**
1. ファインチューニングの実行
   - 学習の実行と進捗モニタリング
   - ハイパーパラメータの調整
   - モデルの評価と改善

---

## **プロジェクト構造**

```
project_root/
├── data/
│   ├── raw/             # 生データセット (PlantVillage)
│   ├── processed/       # 前処理後のデータ
│   │   ├── train/      # 訓練データ
│   │   ├── val/        # 検証データ
│   │   ├── test/       # テストデータ
│   │   └── class_mapping.json
│   └── annotations/     # 必要なラベルデータ
├── models/
│   ├── llama_4bit/      # 量子化済みモデル
│   └── fine_tuned/      # ファインチューニング済みモデル
├── src/
│   ├── data_processing/ # データ前処理スクリプト
│   ├── training/        # モデル学習スクリプト
│   ├── inference/       # 推論用スクリプト
│   └── evaluation/      # 評価スクリプト
├── tests/               # テストコード
├── results/             # 学習や評価結果
├── configs/             # 設定ファイル
├── requirements.txt     # 使用するPythonライブラリの一覧
├── .gitignore          # Git管理対象外ファイル
├── README.md           # プロジェクトの概要
└── CONTRIBUTING.md     # 貢献ガイド
```

---

## **使用技術と環境**

- **ハードウェア**
  - GPU: NVIDIA RTX 4070 Ti (VRAM 12GB)
  - RAM: 32GB
- **OS**: Windows 11
- **ソフトウェアスタック**
  - Python 3.10.11
  - CUDA 12.4
  - ライブラリ: 
    - `torch==2.5.1`
    - `transformers==4.47.1`
    - `accelerate==1.2.1`
    - `bitsandbytes==0.45.0`
    - `wandb==0.19.1`
    - その他必要なライブラリ（requirements.txtを参照）

---

## **データセット**

- **使用データセット**: [PlantVillage Dataset](https://www.kaggle.com/datasets/abdallahalidev/plantvillage-dataset)
- **データ内容**:
  - 15種類の植物の画像
  - 健康な状態と病気の状態を含む
  - 38クラス、54,303枚の画像
  - データ分割比率: 訓練70% / 検証15% / テスト15%

---

## **評価指標**

1. **分類タスク**
   - **精度 (Accuracy)**
   - **F1スコア (F1 Score)**
2. **診断タスク**
   - **ROC-AUC**
   - **平均精度 (mAP)**
3. **提案タスク**
   - ユーザー評価 (主観的に提案の有用性を評価)

---

## **開発フロー**

### **完了したステップ**
1. ✅ 環境構築
   - 仮想環境の構築
   - 必要なライブラリのインストール

2. ✅ データセットの準備
   - PlantVillage Datasetのダウンロード
   - データ前処理スクリプトの実装
   - データの分割と保存

3. ✅ モデルの準備
   - HuggingFaceからの事前学習済みモデルのダウンロード
   - 4-bit量子化の実装
   - 学習環境の検証

### **次のステップ**
4. 📝 ファインチューニング
   - LoRAを用いた効率的な学習
   - ハイパーパラメータの調整
   - 学習進捗のモニタリング

---

## **不明点・質問事項**

1. **診断結果の具体性**: 提案内容の詳細度をどのレベルまで求めるか。
2. **評価基準の目標値**: 評価指標に対する具体的な目標値を設定する必要があるか。
3. **デプロイの環境**: ローカルのみで完結するのか、クラウド環境でのデプロイも考慮するのか。

---

## **ファインチューニングの詳細**

### **実装の特徴**
1. **効率的な学習**
   - LoRA（Low-Rank Adaptation）による省メモリ学習
   - 4-bit量子化による計算効率の向上
   - 勾配累積によるバッチサイズの実効的な拡大

2. **画像処理の最適化**
   - アスペクト比を考慮したタイル分割
   - 動的なパディング処理
   - 正規化パラメータの最適化

3. **評価指標**
   - BLEUスコア: テキスト生成の品質評価
   - F1スコア: 分類精度の評価
   - カスタム評価指標の追加が可能

4. **モニタリングと可視化**
   - Weights & Biasesによる学習過程の可視化
   - リアルタイムな評価指標の追跡
   - エラーログの詳細な記録

### **設定パラメータ**
```json
{
    "model_config": {
        "base_model_path": "models/llama_4bit",
        "output_dir": "models/fine_tuned",
        "torch_dtype": "float16",
        "max_tiles": 4,
        "image_aspect_ratio": "auto"
    },
    "training_config": {
        "num_epochs": 3,
        "batch_size": 2,
        "gradient_accumulation_steps": 8,
        "learning_rate": 2e-4,
        "weight_decay": 0.01,
        "warmup_ratio": 0.03
    }
}
```

### **使用方法**
1. **環境準備**
   ```bash
   pip install -r requirements.txt
   ```

2. **ファインチューニングの実行**
   ```bash
   python src/training/fine_tune.py
   ```

3. **学習の監視**
   - Weights & Biasesダッシュボードにアクセス
   - ログファイルの確認（`logs/training.log`）

4. **結果の評価**
   - 評価指標の確認
   - 生成されたテキストの品質評価
   - エラー分析とモデルの改善

---

